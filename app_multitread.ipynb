{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# import library's\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import csv\n",
    "import urllib.request as req\n",
    "import random\n",
    "from datetime import datetime\n",
    "import pathlib\n",
    "from selenium.webdriver.common.by import *\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "import logging\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from googleapiclient.discovery import build\n",
    "from google.cloud import storage\n",
    "from PIL import Image\n",
    "from seleniumwire import webdriver as proxywebdriver\n",
    "\n",
    "project_init=False\n",
    "if not os.path.isfile('config.csv'):\n",
    "    CONFIG_DF=pd.DataFrame(columns=[\"SUMRUSH_EMAIL\",\"PROXY\",\"GOOGLE_CUSTOM_SEARCH_ENGINE_ID\",\"GOOGLE_CUSTOM_SEARCH_API_KEY\",\"GCS_S3_BUCKET_NAME\",\"GCS_CREDENTIALS_PATH\"])    \n",
    "    CONFIG_DF.to_csv('config.csv',index=False)\n",
    "    project_init=True\n",
    "else:\n",
    "    CONFIG_DF=pd.read_csv('config.csv')\n",
    "\n",
    "if project_init:   \n",
    "    sys.exit('Config And Proxy Just Intilized')\n",
    " \n",
    "with open('config/global_config.json', 'r') as file:\n",
    "    CONFIG_DATA = json.load(file)\n",
    "\n",
    "# GOOGLE_CUSTOM_SEARCH_API_KEY=CONFIG_DATA['GOOGLE_CUSTOM_SEARCH_API_KEY']\n",
    "# GOOGLE_CUSTOM_SEARCH_ENGINE_ID=CONFIG_DATA['GOOGLE_CUSTOM_SEARCH_ENGINE_ID']\n",
    "\n",
    "# GCS_S3_BUCKET_NAME=CONFIG_DATA['GCS_S3_BUCKET_NAME']\n",
    "# GCS_CREDENTIALS_PATH=Path.cwd()+'/'+CONFIG_DATA['GCS_CREDENTIALS_PATH']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _get_gcs_public_url(bucket_name: str, object_name: str, secure: bool=True):\n",
    "    scheme = \"https\" if secure else \"http\"\n",
    "    return f\"{scheme}://storage.googleapis.com/{bucket_name}/{object_name}\"\n",
    "\n",
    "\n",
    "\n",
    "def _upload_to_gcs(bucket_name: str, file_name: str, buffer: bytes):\n",
    "\n",
    "    client = storage.Client.from_service_account_json(GCS_CREDENTIALS_PATH)\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(file_name)\n",
    "    blob.upload_from_string(buffer)\n",
    "\n",
    "    return _get_gcs_public_url(bucket_name, file_name)\n",
    "\n",
    "\n",
    "def rtn_url(image_path,website):\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    with io.BytesIO() as buffer:\n",
    "        image.save(buffer, format=\"PNG\")\n",
    "        \n",
    "        return _upload_to_gcs(GCS_S3_BUCKET_NAME, website+str(time.time()).split('.')[0]+'.png', buffer.getvalue())\n",
    "\n",
    "\n",
    "# Create custom search service\n",
    "custom_search_service = build(\n",
    "    \"customsearch\", \"v1\", developerKey=GOOGLE_CUSTOM_SEARCH_API_KEY\n",
    ")\n",
    "\n",
    "\n",
    "# Get estimated indexed page numbers using the google custom search api\n",
    "def _get_estimated_indexed_pages(service, api_key, cx, domain):\n",
    "    query = f\"site:{domain}\"\n",
    "    response = service.cse().list(q=query, cx=cx, key=api_key).execute()\n",
    "    if 'error' in response:\n",
    "        if response['error']['code'] == 403 and response['error']['errors'][0]['reason'] == 'dailyLimitExceeded':\n",
    "            raise Exception(\"Your daily quota has been exhausted.\")\n",
    "        else:\n",
    "            raise Exception(f\"An error occurred: {response['error']['message']}\")\n",
    "\n",
    "    return response['searchInformation']['totalResults']\n",
    "\n",
    "\n",
    "def get_estimated_pages(domain_with_scheme: str) -> int:\n",
    "    return _get_estimated_indexed_pages(\n",
    "        custom_search_service,\n",
    "        GOOGLE_CUSTOM_SEARCH_API_KEY,\n",
    "        GOOGLE_CUSTOM_SEARCH_ENGINE_ID,\n",
    "        domain_with_scheme\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Create custom search service\n",
    "custom_search_service = build(\n",
    "    \"customsearch\", \"v1\", developerKey=GOOGLE_CUSTOM_SEARCH_API_KEY\n",
    ")\n",
    "\n",
    "\n",
    "# Get estimated indexed page numbers using the google custom search api\n",
    "def _get_estimated_indexed_pages(service, api_key, cx, domain):\n",
    "    query = f\"site:{domain}\"\n",
    "    response = service.cse().list(q=query, cx=cx, key=api_key).execute()\n",
    "    \n",
    "    if 'error' in response:\n",
    "        if response['error']['code'] == 403 and response['error']['errors'][0]['reason'] == 'dailyLimitExceeded':\n",
    "            raise Exception(\"Your daily quota has been exhausted.\")\n",
    "        else:\n",
    "            raise Exception(f\"An error occurred: {response['error']['message']}\")\n",
    "\n",
    "    return response['searchInformation']['totalResults']\n",
    "\n",
    "\n",
    "def get_estimated_pages(domain_with_scheme: str) -> int:\n",
    "    return _get_estimated_indexed_pages(\n",
    "        custom_search_service,\n",
    "        GOOGLE_CUSTOM_SEARCH_API_KEY,\n",
    "        GOOGLE_CUSTOM_SEARCH_ENGINE_ID,\n",
    "        domain_with_scheme\n",
    "    )\n",
    "\n",
    "# import library's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# login system\n",
    "def login():\n",
    "    inp=input('Do you want to Start Login System(Y/N)? ')\n",
    "    if inp.lower()=='y':\n",
    "        options = webdriver.ChromeOptions() \n",
    "        if CONFIG_DATA['SHOW_Window_on_login'].lower()!='yes':\n",
    "            options.add_argument('headless')\n",
    "\n",
    "        driver = webdriver.Chrome(options=options)  # Optional argument, if not specified will search path.\n",
    "        driver.implicitly_wait(10)\n",
    "        print('Starting.....')\n",
    "\n",
    "        # %%\n",
    "        file_path = 'config/smush_account.txt'  # Replace 'your_file.txt' with the actual file path\n",
    "        try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                # Read the entire contents of the file\n",
    "                file_contents = file.read()\n",
    "                file_contents=file_contents.split('\\n')\n",
    "                for i in file_contents:\n",
    "                    driver.get('https://www.semrush.com/')\n",
    "                    try:\n",
    "                        driver.find_element(By.CSS_SELECTOR, \"#srf-search-bar\")\n",
    "                        print(email, 'Just Logged In a while ago')\n",
    "                        continue\n",
    "                    except:\n",
    "                        pass\n",
    "                        \n",
    "                    try:\n",
    "                        driver.find_element(By.CSS_SELECTOR, \".ch2-dialog-actions  .ch2-allow-all-btn\").click()\n",
    "                    except:\n",
    "                        pass\n",
    "                    email=i.split(':')[0]\n",
    "                    password=i.split(':')[1]\n",
    "\n",
    "\n",
    "                    if os.path.exists('smush_cookies/'+email+'_cookies.json'):\n",
    "                        with open('smush_cookies/ijguk787duis@icznn.com_cookies.json', 'r') as file:\n",
    "                            cookies = json.load(file)\n",
    "                            for cookie in cookies:\n",
    "                                driver.add_cookie(cookie)\n",
    "                            driver.refresh()\n",
    "                        try:\n",
    "                            driver.find_element(By.CSS_SELECTOR, \"#srf-search-bar\")\n",
    "                            print(email, 'logged in from before')\n",
    "                            continue\n",
    "                        except:\n",
    "                            pass\n",
    "                        \n",
    "\n",
    "                    driver.find_element(By.CSS_SELECTOR, \"#loginForm #email\").send_keys(email)\n",
    "                    driver.find_element(By.CSS_SELECTOR, \"#loginForm #password\").send_keys(password)\n",
    "                    # driver.find_element(By.CSS_SELECTOR, \"#loginForm button[type=submit]\").click()\n",
    "                    driver.execute_script(\"arguments[0].click()\", driver.find_element(By.CSS_SELECTOR, \"#loginForm button[type=submit]\"))\n",
    "                    time.sleep(10)\n",
    "                    try:\n",
    "                        driver.find_element(By.CSS_SELECTOR, 'button[data-test=\"header-menu__user\"]')\n",
    "                        f=True\n",
    "                        pass\n",
    "                    except Exception as e:\n",
    "                        f=False\n",
    "                        print(email, 'Is Bad Credentials',e)\n",
    "                        pass\n",
    "                    if f==True:\n",
    "                        cookies = driver.get_cookies()\n",
    "                        with open('smush_cookies/'+email+'_cookies.json', 'w') as file:\n",
    "                            json.dump(cookies, file)\n",
    "                        print(email, 'Is logged in succesfully')\n",
    "                        driver.delete_all_cookies()\n",
    "                    \n",
    "            driver.quit()\n",
    "        except FileNotFoundError:\n",
    "            print(f\"The file  was not found.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "    inp=input('Do you want to Login Another Account (Y/N)? ')\n",
    "    if inp.lower()=='y':\n",
    "        login()\n",
    "# login system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if file is csv or excel\n",
    "def is_csv(filename):\n",
    "    # Get the file extension from the filename\n",
    "    file_extension = os.path.splitext(filename)[1].lower()\n",
    "\n",
    "    # Check if the file extension is CSV or Excel\n",
    "    if file_extension in ['.csv']:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "# check if file is csv or excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Account nawedwa.hedi01 , Proxy Ip: 209.163.116.64\n",
      "An error occurred: [Errno 22] Invalid argument: 'smush_cookies\\nawedwa.hedi01@gmail.com_cookies.json'\n"
     ]
    }
   ],
   "source": [
    "def build_selenium_browser(cookie_file,cookie):\n",
    "    rt={'status':False, 'browser':None,'info':None}\n",
    "    pxy=False\n",
    "\n",
    "    temp_driver_df_config=CONFIG_DF[CONFIG_DF['SUMRUSH_EMAIL']=='nawed.wahedi01@gmail.com']\n",
    "    if temp_driver_df_config.empty:\n",
    "        rt['info']='Account Configuration not set.'\n",
    "        return rt\n",
    "    else:\n",
    "        account_config= temp_driver_df_config.iloc[0]\n",
    "        if account_config['PROXY']:\n",
    "            pxy=True\n",
    "    options = webdriver.ChromeOptions() \n",
    "    options.add_argument(\"pageLoadStrategy=none\")\n",
    "    options.add_argument(\"--disable-network-throttling\")\n",
    "    options.add_argument(\"--disable-cpu-throttling\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
    "    options.add_argument(\"--disable-features=NetworkService\")\n",
    "    options.add_argument(\"--window-size=\"+str(CONFIG_DATA['Resolution-W'])+\"x\"+str(CONFIG_DATA['Resolution-H']))\n",
    "    options.add_argument(\"--hide-scrollbars\")\n",
    "    if CONFIG_DATA['SHOW_Window'].lower()!='yes' and False:\n",
    "        options.add_argument('headless')\n",
    "    if pxy==True:\n",
    "        while True:\n",
    "            proxy_options = {\n",
    "                'proxy': {\n",
    "                    'http': 'socks5://'+account_config['PROXY'],\n",
    "                    'https': 'socks5://'+account_config['PROXY'],\n",
    "                    'no_proxy': 'localhost,127.0.0.1'\n",
    "                }\n",
    "            }\n",
    "            driver = proxywebdriver.Chrome(seleniumwire_options=proxy_options,options=options)\n",
    "            driver.implicitly_wait(20)\n",
    "            driver.set_page_load_timeout(20)\n",
    "            # configure proxy driver\n",
    "            try:\n",
    "                driver.get('https://ifconfig.me/ip')\n",
    "                print('Account '+cookie+' , Proxy Ip:',driver.find_element(By.CSS_SELECTOR,'body').text)\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(cookie,'Proxy Not Working ! ',str(e))\n",
    "                inp=input('As Proxy Not working You want to Reconfigure or skip this account?  (Y Reconfigure /N Skip): ')\n",
    "                if inp.lower()=='y':\n",
    "                    inp=input('Press Enter if you reconfigured the Proxy')\n",
    "                    return  build_selenium_browser(cookie_file,cookie)\n",
    "                else:\n",
    "                    rt['info']='Account Skiped due proxy not working '+cookie\n",
    "                return rt\n",
    "\n",
    "\n",
    "    else:\n",
    "        driver = webdriver.Chrome(options=options)  # Optional argument, if not specified will search path.\n",
    "        driver.implicitly_wait(20)\n",
    "        driver.set_page_load_timeout(20)\n",
    "        # configure driver\n",
    "        try:\n",
    "            driver.get('https://ifconfig.me/ip')\n",
    "            print('Account '+cookie+' , Proxy Ip:',driver.find_element(By.CSS_SELECTOR,'body').text())\n",
    "        except:\n",
    "            print(cookie,'Proxy Not Working ! ')\n",
    "            rt['info']='Proxy not working '+cookie\n",
    "            return rt\n",
    "    \n",
    "    try:\n",
    "        driver.get('https://www.semrush.com/')\n",
    "    except TimeoutException:\n",
    "        driver.execute_script(\"window.stop();\")\n",
    "    # load semrush\n",
    "\n",
    "    try:\n",
    "        with open(cookie_file, 'r') as file:\n",
    "            # Read the entire contents of the file\n",
    "            cookies__ = json.load(file)\n",
    "            for cookie__ in cookies__:\n",
    "                driver.add_cookie(cookie__)\n",
    "            driver.refresh()\n",
    "        try:\n",
    "            driver.find_element(By.CSS_SELECTOR, 'button[data-test=\"header-menu__user\"]')\n",
    "            rt['status']=True\n",
    "            rt['browser']=driver            \n",
    "            print(cookie,' Logged in successfully.')\n",
    "            rt['browser']=driver\n",
    "            return rt\n",
    "            pass\n",
    "        except:\n",
    "            print(cookie,'Bad Credential. Try Again ! ')\n",
    "            rt['info']='Bad Credential. Try Again ! '+cookie\n",
    "            return rt\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"The file  was not found. Try again !\")\n",
    "        rt['info']='Bad Credential. Try Again ! '+cookie\n",
    "        return rt\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        rt['info']='An error occurred: {e}\" ! '+cookie\n",
    "        return rt\n",
    "    return rt\n",
    "build_selenium_browser('smush_cookies\\nawedwa.hedi01@gmail.com_cookies.json','nawedwa.hedi01')\n",
    "\n",
    "\n",
    "# def threads_init():\n",
    "#     print('Initlizing Threads')\n",
    "#     folder_path = 'smush_cookies'  # Replace with the actual path to your folder\n",
    "\n",
    "#     # Get a list of all files in the folder\n",
    "#     file_list = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "#     drivers={}\n",
    "#     # Print the list of file names\n",
    "#     for file in file_list:\n",
    "#         thread_path=folder_path+'/'+file\n",
    "#         thread_name=file.replace('_cookies.json','')\n",
    "#         print('\\n\\nIntializing Tread',thread_name)\n",
    "#         build_selenium_browser(thread_path,thread_name)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# threads_init()\n",
    "\n",
    "# if __name__ == \"__main__\" or True:\n",
    "if False:\n",
    "    login()\n",
    "    # intilize data files\n",
    "    print('Intializing Data Files.....')\n",
    "    while True:\n",
    "        filename = input('Write Your Data File Name(Usa1.xlsx): ')\n",
    "        file_path='data_files/'+filename\n",
    "        if os.path.isfile(file_path):\n",
    "            break\n",
    "        else:\n",
    "            print(f\"The file {file_path} does not exist. Try Again.\")\n",
    "            continue\n",
    "\n",
    "    if is_csv(file_path):\n",
    "        df=pd.read_csv(file_path)\n",
    "    else:\n",
    "        df=pd.read_excel(file_path)\n",
    "    if not \"Authority Score\" in df.columns:\n",
    "        df['Authority Score'] = None\n",
    "    if not \"Organic Search Traffic\" in df.columns:\n",
    "        df['Organic Search Traffic'] = None\n",
    "    if not \"ImageURL\" in df.columns:\n",
    "        df['ImageURL'] = None\n",
    "    if not \"Page View\" in df.columns:\n",
    "        df['Page View'] = None\n",
    "    \n",
    "    if is_csv(file_path):\n",
    "        df=df.to_csv(file_path,index=False)\n",
    "    else:\n",
    "        df=df.to_excel(file_path,index=False)\n",
    "    \n",
    "    thds=threads_init()\n",
    "\n",
    "    \n",
    "    \n",
    "    # intilize data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
